{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 交叉熵(了解)\n",
    "在机器学习中,逻辑回归交叉熵可被用来定义一个损失函数. 真实概率 pipi  是真实标签, 且已知的分布 qiqi  是当前模型的预言值.\n",
    "\n",
    "具体地, 考虑逻辑回归. 前面介绍过, 它处理给定的数据点的集合在两个可能的类别0和1之间的分类.\n",
    "\n",
    "因此,对于一个输入矢量  xx , 逻辑回归模型预测一个输出 y∈{0,1}y∈{0,1} .\n",
    "\n",
    "概率由逻辑函数 g(z)=1/(1+e−z)g(z)=1/(1+e−z) 来表达(建模).\n",
    "\n",
    "换句话说, 输出为 y=1y=1 的概率为\n",
    "\n",
    "qy=1 = ŷ  ≡ g(w⋅x) =1/(1+e−w⋅x)qy=1 = y^ ≡ g(w⋅x) =1/(1+e−w⋅x) ,\n",
    "\n",
    "其中,权重矢量 ww  由合适的算法如梯度下降来优化.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-10,10,1000)\n",
    "y = 1/(1+np.exp(-x))\n",
    "plt.plot(x,y, \"-\")\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似地, 发现 $y=0$的概率由下式给出:\n",
    "\n",
    "$q_{{y=0}}\\ =\\ 1-{\\hat  {y}}$\n",
    "\n",
    "同理,真实 (观测) 概率(probabilities)可表示为$ p_{{y=1}}=y$ and $p_{{y=0}}=1-y$.\n",
    "\n",
    "可这样标记: $ p\\in \\{y,1-y\\}$ 和 $q\\in \\{{\\hat{y}},1-{\\hat{y}}\\}$, 我们可以利用交叉熵得到$p$ 和 $q$之间相异程度的一个度量:\n",
    "\n",
    "$H(p,q)\\ =\\ -\\sum _{i}p_{i}\\log q_{i}\\ =\\ -y\\log {\\hat{y}}-(1-y)\\log(1-{\\hat{y}})$\n",
    "\n",
    "人们在逻辑回归中使用的典型的损失函数是这样计算的: 取样本的所有交叉熵的平均值. \n",
    "\n",
    "例如, 假设我们有$N$个样本,每个样本记为$n=1,\\dots ,N$. 损失函数由下式给出:\n",
    "$$\n",
    " {\\begin{aligned}J(\\mathbf {w} )\\ &=\\ {\\frac {1}{N}}\\sum _{n=1}^{N}H(p_{n},q_{n})\\ =\\ -{\\frac {1}{N}}\\sum _{n=1}^{N}\\ {\\bigg [}y_{n}\\log {\\hat {y}}_{n}+(1-y_{n})\\log(1-{\\hat {y}}_{n}){\\bigg ]}\\,,\\end{aligned}}\n",
    "$$\n",
    "其中 ${\\hat {y}}_{n}\\equiv g(\\mathbf {w} \\cdot \\mathbf {x} _{n})=1/(1+e^{-\\mathbf {w} \\cdot \\mathbf {x} _{n}})$,\n",
    "$ g(z)$是逻辑函数.\n",
    "\n",
    "逻辑损失函数有时也称为交叉熵损失. 也称 \"log loss\" (这种情形, 二元标签常表示为$\\{-1,+1\\}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
