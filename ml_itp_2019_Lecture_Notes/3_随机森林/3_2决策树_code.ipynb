{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log  \n",
    " \n",
    "def calc_shannon_ent(data_set):  \n",
    "    \"\"\" \n",
    "    计算香农熵 \n",
    "    :param data_set:数据集 \n",
    "    :return: 计算结果 \n",
    "    \"\"\"  \n",
    "    num_entries = len(data_set) #保存数据集中实例的总数  \n",
    "    label_counts = {}  \n",
    "    #-----------------------  \n",
    "    # 为所有可能分类创建字典  \n",
    "    #-----------------------  \n",
    "    for vec in data_set: # 遍历每个实例，统计标签的频数  \n",
    "        current_label = vec[-1]  #设样本的最后一列的数值为键值  \n",
    "        if current_label not in label_counts.keys():  \n",
    "            label_counts[current_label] = 0  \n",
    "        label_counts[current_label] += 1  \n",
    "    shannon_ent = 0.0  \n",
    "    for key in label_counts:  \n",
    "        prob = float(label_counts[key]) / num_entries  \n",
    "        shannon_ent -= prob * log(prob,2) # 以2为底的对数  \n",
    "    return shannon_ent  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建数据集  \n",
    "def create_data_set():  \n",
    "    data_set = [[1,1,'y'],  \n",
    "                [1,1,'y'],  \n",
    "                [1,0,'n'],  \n",
    "                [0,0,'n'],  \n",
    "                [0,1,'n']  \n",
    "                ]  \n",
    "    labels = ['gill', 'fin']  \n",
    "    return data_set, labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'y'], [1, 1, 'y'], [1, 0, 'n'], [0, 0, 'n'], [0, 1, 'n']]\n",
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "#使用自定义函数来计算香农熵\n",
    "my_data,labels = create_data_set()  \n",
    "print(my_data) \n",
    "print(calc_shannon_ent(my_data))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'y'], [1, 1, 'y'], [1, 0, 'n'], [0, 0, 'n'], [0, 1, 'not sure']]\n",
      "1.5219280948873621\n"
     ]
    }
   ],
   "source": [
    "#如果有更多的分类呢?  \n",
    "my_data[-1][-1]='not sure'  \n",
    "print(my_data)  \n",
    "print(calc_shannon_ent(my_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'y'], [1, 1, 'y'], [1, 0, 'n'], [0, 0, 'n'], [0, 1, 'n']]\n",
      "[[0, 'n'], [1, 'n']]\n",
      "[[1, 1], [1, 1]]\n",
      "[[1, 'y'], [1, 'y'], [0, 'n']]\n"
     ]
    }
   ],
   "source": [
    "# 划分数据集\n",
    "def split_data_set(data_set, axis, value):  \n",
    "    ''''' \n",
    "    按照给定特征划分数据集 \n",
    "    :param data_set:待划分的数据集 \n",
    "    :param axis:划分数据集所用的特征 \n",
    "    :param value: 特征的返回值 \n",
    "    :return: 划分结果列表 \n",
    "    '''  \n",
    "    ret_data_set = []   # 为了不修改原始数据,新建一个列表  \n",
    "    for vec in data_set:  # vec: 样本, 某一行的数据  \n",
    "        if vec[axis] == value:  \n",
    "            reduced_vec = vec[:axis]    \n",
    "            reduced_vec.extend(vec[axis+1:])  \n",
    "            ret_data_set.append(reduced_vec)  \n",
    "    return ret_data_set  \n",
    "  \n",
    "my_data,labels = create_data_set()  \n",
    "print(my_data) \n",
    "print(split_data_set(my_data,0,0) )\n",
    "print(split_data_set(my_data,2,\"y\") )\n",
    "print(split_data_set(my_data,1,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_data:\n",
      "[[1, 1, 'y'], [1, 1, 'y'], [1, 0, 'n'], [0, 0, 'n'], [0, 1, 'n']]\n",
      "best feature:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 选择最好的划分方式\n",
    "def best_feature_to_split(data_set): # data_set 必须是以长度相同的列表为元素的列表. 每个样本的最后一个元素是当前样本的类别标签  \n",
    "    num_features = len(data_set[0])-1   # 求出当前数据集包含的特征的数目.  \n",
    "    base_entropy = calc_shannon_ent(data_set) # 求出原始香农值  \n",
    "    best_info_gain = 0.0   \n",
    "    best_feature = -1  \n",
    "    for i in range(num_features): # 遍历所有特征  \n",
    "        feat_list = [example[i] for example in data_set] # 将所有第i个特征值或所有可能存在的值写入新列表  \n",
    "        unique_values = set(feat_list)   # 去除重复元素  \n",
    "        new_entropy = 0.0   \n",
    "        for value in unique_values: #遍历所有唯一特征值  \n",
    "            sub_data_set = split_data_set(data_set,i, value) #对每个特征划分一次数据集  \n",
    "            prob = len(sub_data_set)/float(len(data_set))  \n",
    "            new_entropy += prob * calc_shannon_ent(sub_data_set) # 计算数据集的新的香农熵.   \n",
    "        info_gain = base_entropy - new_entropy  \n",
    "        if (info_gain > best_info_gain):  \n",
    "            best_info_gain = info_gain  \n",
    "            best_feature = i  \n",
    "        return best_feature  \n",
    "\n",
    "my_data, labels = create_data_set()  \n",
    "print(\"my_data:\")  \n",
    "print(my_data)  \n",
    "print(\"best feature:\")  \n",
    "print(best_feature_to_split(my_data))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini指数\n",
    "def cal_gini_index(data_set):  \n",
    "    \"\"\"计算给定数据集的Gini指数 \n",
    "    input: data(list): 数据集\n",
    "    output: gini(float): Gini指数\n",
    "    \"\"\"  \n",
    "    # Total no. of the sample  \n",
    "    total_sample = len(data_set)  \n",
    "    if len(data_set)==0:  \n",
    "        return 0  \n",
    "    # Count the no. of labels in the data set  \n",
    "    label_counts = label_uniq_counts(data_set)  \n",
    "  \n",
    "    # Calculate the Gini index of the data set  \n",
    "    gini = 0  \n",
    "    for label in label_counts:  \n",
    "        gini = gini + pow(label_counts[label],2)  \n",
    "  \n",
    "    gini = 1 - float(gini)/ pow(total_sample,2)  \n",
    "    return gini    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 2, 'n': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算数据集中类别标签的个数\n",
    "from math import pow  \n",
    "  \n",
    "def label_uniq_counts(data):  \n",
    "    \"\"\" \n",
    "    input: data(list) \n",
    "    output: label_uniq_counts(int) \n",
    "    \"\"\"  \n",
    "    label_uniq_count ={}  \n",
    "  \n",
    "    for x in data:  \n",
    "        label = x[len(x)-1] # 取得每个样本的类标签label  \n",
    "        if label not in label_uniq_count:  # WHY?  \n",
    "            label_uniq_count[label] = 0  \n",
    "        label_uniq_count[label]  += 1  \n",
    "    return label_uniq_count  \n",
    "\n",
    "label_uniq_counts(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  [[1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "y: [1 1 0 0 0]\n",
      "测试样本为各类的概率: [[0. 1.]\n",
      " [1. 0.]]\n",
      "分类预测结果 [1 0]\n"
     ]
    }
   ],
   "source": [
    "# 训练决策树 (Geron)  \n",
    "# 1. 导入模块  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "import numpy as np  \n",
    "    \n",
    "#2. 创建自己的数据集  \n",
    "  \n",
    "#create dataset  \n",
    "class Fish:  \n",
    "    def __init__(self):  \n",
    "        X = [[1,1],  \n",
    "             [1,1],  \n",
    "             [1,0],  \n",
    "             [0,1],  \n",
    "             [0,1]  \n",
    "             ]  \n",
    "        y = [1,1,0,0,0]  \n",
    "        self.data = np.array(X)  \n",
    "        self.label = np.array(y)  \n",
    "        self.feature = np.array(['鳃','鳍'])     \n",
    "# 训练集  \n",
    "fs = Fish()  \n",
    "  \n",
    "print('X: ', fs.data)  \n",
    "print('y:',fs.label)    \n",
    "  \n",
    "# 训练集的特征  \n",
    "X = fs.data  \n",
    "# 训练集的标签  \n",
    "y = fs.label  \n",
    "  \n",
    "#3.1 分类器这个类之实例化  \n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)  \n",
    "# 3.2 最终生成决策树模型  \n",
    "tree_clf.fit(X,y)  \n",
    "  \n",
    "# 传入一个数据集,用决策树做预测  \n",
    "# predict_proba(测试集): 返回值: 一个ndarray数组,其行数为样本个数,其列数为种类数.  \n",
    "a = tree_clf.predict_proba([[1,1],[0,0]])  \n",
    "# predict(测试集): 函数的返回值: 一个一维array数组,其列数为样本个数  \n",
    "b = tree_clf.predict([[1,0]])  \n",
    "c = tree_clf.predict([[1,1],[1,0]])  \n",
    "print('测试样本为各类的概率:',a)  \n",
    "print('分类预测结果',c)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
